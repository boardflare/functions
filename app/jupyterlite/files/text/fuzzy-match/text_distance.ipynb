{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `text_distance`\n",
    "\n",
    "## Overview\n",
    "Uses the Python [textdistance](https://github.com/life4/textdistance) library which implements edit distance, token, sequence, and phonetic algorithms to calculate the similarity between two strings.\n",
    "\n",
    "| Task | Description | Boardflare RUNPY() | Excel PY() | Source in Jupyter | Demo Workbook |\n",
    "|:----:|:------------|:-------:|:----------:|:-------:|:-------:|\n",
    "| [Fuzzy Matching](https://www.boardflare.com/tasks/nlp/fuzzy-match) | Uses [textdistance](https://github.com/life4/textdistance) library which implements the broadest range of algorithms. | âœ… | - | [Open](https://addins.boardflare.com/functions/prod/jupyterlite/lab/index.html?path=text/fuzzy-match/text_distance.ipynb) | [Open](https://whistlernetworks.sharepoint.com/:x:/s/Boardflare/Eb_nCI4mR6tImGx_S1hPVs8B4UYmrJRrkk0_Grai6A4adg?e=xfUuNQ) |\n",
    "\n",
    "## Usage\n",
    "\n",
    "Compares `lookup_value` with each value in the `lookup_array` and returns the index of the closest match and a normalized similarity score (within a given algorithm) between 0 and 1 (higher is more similar).\n",
    "\n",
    "```python\n",
    "text_distance(lookup_value, lookup_array, algorithm)\n",
    "```\n",
    "\n",
    "Arguments:\n",
    "\n",
    "| Argument       | Positional | Type           | Description                                                                 |\n",
    "|----------------|------------|----------------|-----------------------------------------------------------------------------|\n",
    "| `lookup_value` | arg1       | string or list | String(s) to compare with the strings in the `lookup_array`.                |\n",
    "| `lookup_array` | arg2       | list           | A list of strings to compare with the `lookup_value`.                       |\n",
    "| `algorithm`    | arg3       | string         | Specifies the [similarity algorithm](#similarity-algorithms) to use.   |\n",
    "\n",
    "Returns an array with two columns:\n",
    "\n",
    "| Return Value | Type  | Description                                                                                  |\n",
    "|--------------|-------|----------------------------------------------------------------------------------------------|\n",
    "| Index        | int   | Index of the closest matching string in the `lookup_array` to each `lookup_value`.           |\n",
    "| Similarity   | float | The similarity score between 0 and 1, where a higher score indicates more similarity.        |\n",
    "\n",
    "### BOARDFLARE.RUNPY\n",
    "\n",
    "```excel\n",
    "=BOARDFLARE.RUNPY(\"text/fuzzy-match/text_distance.ipynb\", lookup_value, lookup_array, algorithm)\n",
    "```\n",
    "For example, to calculate the similarity between the string `\"example\"` and an array constant `{\"samples\", \"exemplar\", \"sample\", \"examples\"}` using the Jaccard algorithm, you would use the following formula, which returns `1, 0.875`, which is `exemplar`.\n",
    "\n",
    "```excel\n",
    "=BOARDFLARE.RUNPY(\"text/fuzzy-match/text_distance.ipynb\", \"example\", {\"samples\", \"exemplar\", \"examples\"}, \"jaccard\")\n",
    "```\n",
    "\n",
    "### LAMBDA\n",
    "\n",
    "These functions are similar to the `XMATCH` and `XLOOKUP` functions in Excel, but with the added ability to set a similarity threshold.\n",
    "\n",
    "**FUZZYMATCH.TD**\n",
    "\n",
    "Provides features similar to `XMATCH`, but with the ability to set a similarity threshold and algorithm. The default algorithm is `jaccard` and similarity_threshold is `0.7`.\n",
    "\n",
    "```excel\n",
    "=LAMBDA(lookup_value, lookup_array, [similarity_threshold], [algorithm],\n",
    "    LET(\n",
    "        threshold, IF(ISOMITTED(similarity_threshold), 0.7, similarity_threshold),\n",
    "        algo, IF(ISOMITTED(algorithm), \"jaccard\", algorithm),\n",
    "        result, BOARDFLARE.RUNPY(\"text/fuzzy-match/text_distance.ipynb\", lookup_value, lookup_array, algo),\n",
    "        index, INDEX(result, 1),\n",
    "        score, INDEX(result, 2),\n",
    "        IF(score >= threshold, index, \"No match\")\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "```excel\n",
    "=FUZZYMATCH.TD(A1, B1:B10, 0.8)\n",
    "```\n",
    "\n",
    "**FUZZYLOOKUP.TD**\n",
    "\n",
    "Provides features similar to `XLOOKUP`, with the ability to return a row from a `return_array`. Otherwise the same as `FUZZYMATCH.TD`.\n",
    "\n",
    "```excel\n",
    "=LAMBDA(lookup_value, lookup_array, return_array, [similarity_threshold], [algorithm],\n",
    "    LET(\n",
    "        threshold, IF(ISOMITTED(similarity_threshold), 0.7, similarity_threshold),\n",
    "        algo, IF(ISOMITTED(algorithm), \"jaccard\", algorithm),\n",
    "        result, BOARDFLARE.RUNPY(\"text/fuzzy-match/text_distance.ipynb\", lookup_value, lookup_array, algo),\n",
    "        index, INDEX(result, 1),\n",
    "        score, INDEX(result, 2),\n",
    "        IF(score >= threshold, INDEX(return_array, index), \"No match\")\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "```excel\n",
    "=FUZZYLOOKUP.TD(A1, B1:B10, C1:E10, 0.8, \"jaccard\")\n",
    "```\n",
    "\n",
    "## Similarity Algorithms\n",
    "\n",
    "The similarity algorithms available in `textdistance` are given in the tables below.\n",
    "\n",
    "### Edit Distance\n",
    "\n",
    "| Algorithm            | Description                                                                 |\n",
    "|----------------------|-----------------------------------------------------------------------------|\n",
    "| [`damerau_levenshtein`](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance) | Similar to Levenshtein but considers transpositions as a single edit. |\n",
    "| [`hamming`](https://en.wikipedia.org/wiki/Hamming_distance)            | Measures the number of positions at which the corresponding symbols are different. |\n",
    "| [`levenshtein`](https://en.wikipedia.org/wiki/Levenshtein_distance)        | Calculates the minimum number of single-character edits required to change one word into the other. |\n",
    "| [`jaro`](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)               | Measures similarity between two strings, giving more weight to common prefixes. |\n",
    "| [`jaro_winkler`](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)       | An extension of Jaro, giving more weight to strings that match from the beginning. |\n",
    "| [`lcsseq`](https://en.wikipedia.org/wiki/Longest_common_subsequence_problem)             | Measures the longest common subsequence. |\n",
    "| [`lcsstr`](https://docs.python.org/2/library/difflib.html#difflib.SequenceMatcher)             | Measures the longest common substring. |\n",
    "| [`ratcliff_obershelp`](https://en.wikipedia.org/wiki/Gestalt_Pattern_Matching) | Measures similarity based on the longest common subsequence. |\n",
    "| [`strcmp95`](http://cpansearch.perl.org/src/SCW/Text-JaroWinkler-0.1/strcmp95.c)           | A string comparison algorithm developed by the U.S. Census Bureau. |\n",
    "| [`needleman_wunsch`](https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm)   | A dynamic programming algorithm for sequence alignment. |\n",
    "| [`smith_waterman`](https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm)     | A dynamic programming algorithm for local sequence alignment. |\n",
    "| [`gotoh`](http://bioinfo.ict.ac.cn/~dbu/AlgorithmCourses/Lectures/LOA/Lec6-Sequence-Alignment-Affine-Gaps-Gotoh1982.pdf)              | An extension of Needleman-Wunsch with affine gap penalties. |\n",
    "\n",
    "### Token\n",
    "\n",
    "| Algorithm            | Description                                                                 |\n",
    "|----------------------|-----------------------------------------------------------------------------|\n",
    "| [`cosine`](https://en.wikipedia.org/wiki/Cosine_similarity)             | Measures the cosine of the angle between two non-zero vectors. |\n",
    "| [`jaccard`](https://en.wikipedia.org/wiki/Jaccard_index)            | Measures similarity between finite sample sets. |\n",
    "| [`overlap`](https://en.wikipedia.org/wiki/Overlap_coefficient)            | Measures the overlap coefficient between two sets. |\n",
    "| [`sorensen`](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)           | Measures similarity between two sets, based on the size of the intersection divided by the size of the union. |\n",
    "| [`sorensen_dice`](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)      | Similar to Sorensen, but uses Dice's coefficient. |\n",
    "| [`dice`](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)               | Another name for Sorensen-Dice coefficient. |\n",
    "| [`tversky`](https://en.wikipedia.org/wiki/Tversky_index)            | A generalization of the Jaccard index. |\n",
    "\n",
    "### Sequence\n",
    "\n",
    "| Algorithm            | Description                                                                 |\n",
    "|----------------------|-----------------------------------------------------------------------------|\n",
    "| [`bag`](https://github.com/Yomguithereal/talisman/blob/master/src/metrics/bag.js)                | Measures bag similarity between two sequences                               |\n",
    "| [`mlipns`](http://www.sial.iias.spb.su/files/386-386-1-PB.pdf)             | Measures similarity using the MLIPNS algorithm                              |\n",
    "| [`monge_elkan`](https://www.academia.edu/200314/Generalized_Monge-Elkan_Method_for_Approximate_Text_String_Comparison)        | A hybrid algorithm combining multiple similarity measures. $ME(a,b)$ |\n",
    "\n",
    "### Phonetic\n",
    "\n",
    "| Algorithm                                                                    | Description                                                                 |\n",
    "|------------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| [`mra`](https://en.wikipedia.org/wiki/Match_rating_approach)                 | Measures similarity using the MRA algorithm                                 |\n",
    "| [`editex`](https://anhaidgroup.github.io/py_stringmatching/v0.3.x/Editex.html) | Measures similarity using the Editex algorithm                              |                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textdistance\n",
    "\n",
    "# Basic usage of the textdistance library\n",
    "# Compute the normalized similarity of two strings\n",
    "textdistance.hamming.normalized_similarity('test', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>needles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exemplary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     needles\n",
       "0     sample\n",
       "1  exemplary\n",
       "2    sampler\n",
       "3    example"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Setup globals similar to RUNPY function.\n",
    "# Arrays must be in pandas DataFrame.\n",
    "arg1 = pd.DataFrame([\"sample\", \"exemplary\", \"sampler\", \"example\"], columns=['needles'])\n",
    "arg2 = pd.DataFrame([\"samples\", \"exemplar\", \"sample\", \"examples\"], columns=['haystack'])\n",
    "arg3 = 'jaccard'\n",
    "\n",
    "arg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1.0], [2, 0.89], [3, 0.86], [2, 0.88]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textdistance\n",
    "import pandas as pd\n",
    "\n",
    "def text_distance(needle, haystack_df, algorithm='jaccard'):\n",
    "    # Get the algorithm function from textdistance\n",
    "    algo_func = getattr(textdistance, algorithm)\n",
    "    # Flatten the DataFrame to a list\n",
    "    haystack = haystack_df.values.flatten().tolist()\n",
    "    \n",
    "    # Check if needle is a DataFrame\n",
    "    if isinstance(needle, pd.DataFrame):\n",
    "        needle_list = needle.values.flatten().tolist()\n",
    "    else:\n",
    "        needle_list = [needle]\n",
    "    \n",
    "    results = [] \n",
    "    for needle_item in needle_list:\n",
    "        # Calculate similarity scores with normalization and round to 2 decimal places\n",
    "        # Adjust index to be 1-based\n",
    "        scores = [(index + 1, round(algo_func.normalized_similarity(needle_item, item), 2)) for index, item in enumerate(haystack)]\n",
    "        # Sort based on scores in descending order\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        # Append the top index and score to results as a list\n",
    "        results.append(list(scores[0]))\n",
    "\n",
    "    # results is 2D list, e.g. [[1, 0.75], [2, 0.85]]\n",
    "    return results\n",
    "\n",
    "text_distance(arg1, arg2, arg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Algorithm', 'Closest Match', 'Score'],\n",
       " ['jaccard', 3, 1.0],\n",
       " ['levenshtein', 3, 1.0],\n",
       " ['hamming', 3, 1.0],\n",
       " ['cosine', 3, 1.0],\n",
       " ['jaro', 3, 1.0],\n",
       " ['jaro_winkler', 3, 1.0],\n",
       " ['sorensen', 3, 1.0],\n",
       " ['ratcliff_obershelp', 3, 1.0],\n",
       " ['damerau_levenshtein', 3, 1.0],\n",
       " ['strcmp95', 3, 1.0],\n",
       " ['needleman_wunsch', 3, 1.0],\n",
       " ['smith_waterman', 3, 1.0],\n",
       " ['tversky', 3, 1.0],\n",
       " ['overlap', 3, 1.0],\n",
       " ['monge_elkan', 3, 1.0],\n",
       " ['lcsseq', 3, 1.0],\n",
       " ['lcsstr', 3, 1.0],\n",
       " ['gotoh', 3, 1.0],\n",
       " ['sorensen_dice', 3, 1.0],\n",
       " ['dice', 3, 1.0],\n",
       " ['bag', 3, 1.0],\n",
       " ['editex', 3, 1.0],\n",
       " ['mlipns', 1, 1.0],\n",
       " ['mra', 3, 1.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of algorithms to test\n",
    "algorithms = [\n",
    "    'jaccard', 'levenshtein', 'hamming', 'cosine', 'jaro', 'jaro_winkler', \n",
    "    'sorensen', 'ratcliff_obershelp', 'damerau_levenshtein', 'strcmp95', \n",
    "    'needleman_wunsch', 'smith_waterman', 'tversky', 'overlap', 'monge_elkan',\n",
    "    'lcsseq', 'lcsstr', 'gotoh', 'sorensen_dice', 'dice', 'bag', 'editex', \n",
    "    'mlipns', 'mra'\n",
    "]\n",
    "\n",
    "# Example needle and haystack DataFrame\n",
    "needle = \"sampling\"\n",
    "haystack_df = pd.DataFrame([\"sample\", \"example\", \"sampling\", \"test\"])\n",
    "\n",
    "# Calculate results for each algorithm\n",
    "results = [['Algorithm', 'Closest Match', 'Score']]\n",
    "for algo in algorithms:\n",
    "    match, score = text_distance(needle, haystack_df, algo)[0]\n",
    "    results.append([algo, match, float(score)])\n",
    "\n",
    "# Return results as a nested list with headers\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
