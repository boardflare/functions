{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "description"
    ]
   },
   "source": [
    "# Azure AI Sentiment Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use the Azure AI Text Analytics service to perform sentiment analysis on a dataset of tweets. The dataset is a collection of tweets about the COVID-19 vaccine. The goal is to determine the sentiment of each tweet as positive, negative, or neutral.\n",
    "\n",
    "## Compatibility\n",
    "BOARDFLARE.RUNPY ✅  \n",
    "Python in Excel ❌\n",
    "\n",
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: micropip in c:\\users\\brent\\code\\functions\\venv\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\users\\brent\\code\\functions\\venv\\lib\\site-packages (from micropip) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install micropip\n",
    "import micropip\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "arg1"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\"The food and service were unacceptable. The concierge was nice, however.\"], [\"The rooms were clean and well maintained.\"], [\"The location is perfect but the staff was rude.\"]]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arg1 is a column of text data\n",
    "arg1 = pd.DataFrame([\n",
    "    \"The food and service were unacceptable. The concierge was nice, however.\",\n",
    "    \"The rooms were clean and well maintained.\",\n",
    "    \"The location is perfect but the staff was rude.\"\n",
    "])\n",
    "\n",
    "# arg1 is a single string\n",
    "# arg1 = \"The food and service were unacceptable. The concierge was nice, however.\"\n",
    "\n",
    "# output arg1 as column vector\n",
    "json.dumps([[x] for x in arg1[0].values.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "arg2"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7920c673894d49d292de11a80d165725'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Azure language api key\n",
    "arg2 = '7920c673894d49d292de11a80d165725'\n",
    "arg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "arg3"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://boardflare.openai.azure.com/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Azure language api endpoint\n",
    "arg3 = 'https://boardflare.openai.azure.com/'\n",
    "arg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  'mixed',\n",
       "  0.3,\n",
       "  0.17,\n",
       "  0.52,\n",
       "  'The food and service were unacceptable. ',\n",
       "  'negative',\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  'food',\n",
       "  'negative',\n",
       "  0.01,\n",
       "  0.99,\n",
       "  'unacceptable',\n",
       "  'negative',\n",
       "  0.01,\n",
       "  0.99],\n",
       " [1,\n",
       "  'mixed',\n",
       "  0.3,\n",
       "  0.17,\n",
       "  0.52,\n",
       "  'The food and service were unacceptable. ',\n",
       "  'negative',\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  'service',\n",
       "  'negative',\n",
       "  0.01,\n",
       "  0.99,\n",
       "  'unacceptable',\n",
       "  'negative',\n",
       "  0.01,\n",
       "  0.99],\n",
       " [1,\n",
       "  'mixed',\n",
       "  0.3,\n",
       "  0.17,\n",
       "  0.52,\n",
       "  'The concierge was nice, however.',\n",
       "  'positive',\n",
       "  0.61,\n",
       "  0.35,\n",
       "  0.05,\n",
       "  'concierge',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0,\n",
       "  'nice',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0],\n",
       " [2,\n",
       "  'positive',\n",
       "  0.86,\n",
       "  0.14,\n",
       "  0.0,\n",
       "  'The rooms were clean and well maintained.',\n",
       "  'positive',\n",
       "  0.86,\n",
       "  0.14,\n",
       "  0.0,\n",
       "  'rooms',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0,\n",
       "  'clean',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0],\n",
       " [2,\n",
       "  'positive',\n",
       "  0.86,\n",
       "  0.14,\n",
       "  0.0,\n",
       "  'The rooms were clean and well maintained.',\n",
       "  'positive',\n",
       "  0.86,\n",
       "  0.14,\n",
       "  0.0,\n",
       "  'rooms',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0,\n",
       "  'well maintained',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0],\n",
       " [3,\n",
       "  'negative',\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  'The location is perfect but the staff was rude.',\n",
       "  'negative',\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  'location',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0,\n",
       "  'perfect',\n",
       "  'positive',\n",
       "  1.0,\n",
       "  0.0],\n",
       " [3,\n",
       "  'negative',\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  'The location is perfect but the staff was rude.',\n",
       "  'negative',\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  'staff',\n",
       "  'negative',\n",
       "  0.03,\n",
       "  0.97,\n",
       "  'rude',\n",
       "  'negative',\n",
       "  0.03,\n",
       "  0.97]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await micropip.install([\"azure-ai-textanalytics\"])\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Example method for detecting sentiment and opinions in text \n",
    "def azure_sentiment(documents, language_key, language_endpoint):\n",
    "    \"\"\"\n",
    "    Analyzes sentiment and opinions in the provided documents using Azure Text Analytics.\n",
    "\n",
    "    Parameters:\n",
    "    documents (str or DataFrame): The text documents to analyze. Can be a single string or a pandas DataFrame.\n",
    "    language_key (str): The Azure Text Analytics API key.\n",
    "    language_endpoint (str): The Azure Text Analytics API endpoint.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of lists containing the sentiment analysis results. Each inner list contains:\n",
    "        - Document index (1-based)\n",
    "        - Document sentiment\n",
    "        - Document confidence scores (positive, neutral, negative)\n",
    "        - Sentence text\n",
    "        - Sentence sentiment\n",
    "        - Sentence confidence scores (positive, neutral, negative)\n",
    "        - Target text\n",
    "        - Target sentiment\n",
    "        - Target confidence scores (positive, negative)\n",
    "        - Assessment text\n",
    "        - Assessment sentiment\n",
    "        - Assessment confidence scores (positive, negative)\n",
    "    \"\"\"\n",
    "    # Check if documents is a string, list, or DataFrame\n",
    "    if isinstance(documents, str):\n",
    "        documents = [documents]\n",
    "    elif isinstance(documents, pd.DataFrame):\n",
    "        documents = documents.values.flatten().tolist()  # Convert df to list\n",
    "\n",
    "    # Authenticate the client using your key and endpoint \n",
    "    ta_credential = AzureKeyCredential(language_key)\n",
    "    client = TextAnalyticsClient(\n",
    "            endpoint=language_endpoint, \n",
    "            credential=ta_credential)\n",
    "\n",
    "    result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
    "    doc_result = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for idx, document in enumerate(doc_result):\n",
    "        for sentence in document.sentences:\n",
    "            for mined_opinion in sentence.mined_opinions:\n",
    "                target = mined_opinion.target\n",
    "                for assessment in mined_opinion.assessments:\n",
    "                    data.append([\n",
    "                        idx + 1,  # 1-based index\n",
    "                        document.sentiment,\n",
    "                        document.confidence_scores.positive,\n",
    "                        document.confidence_scores.neutral,\n",
    "                        document.confidence_scores.negative,\n",
    "                        sentence.text,\n",
    "                        sentence.sentiment,\n",
    "                        sentence.confidence_scores.positive,\n",
    "                        sentence.confidence_scores.neutral,\n",
    "                        sentence.confidence_scores.negative,\n",
    "                        target.text,\n",
    "                        target.sentiment,\n",
    "                        target.confidence_scores.positive,\n",
    "                        target.confidence_scores.negative,\n",
    "                        assessment.text,\n",
    "                        assessment.sentiment,\n",
    "                        assessment.confidence_scores.positive,\n",
    "                        assessment.confidence_scores.negative\n",
    "                    ])\n",
    "    print(data)\n",
    "    return data\n",
    "\n",
    "azure_sentiment(arg1, arg2, arg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Analyzes sentiment and opinions in the provided documents using Azure Text Analytics.\\n\\n    Parameters:\\n    documents (str or DataFrame): The text documents to analyze. Can be a single string or a pandas DataFrame.\\n    language_key (str): The Azure Text Analytics API key.\\n    language_endpoint (str): The Azure Text Analytics API endpoint.\\n\\n    Returns:\\n    list: A list of lists containing the sentiment analysis results. Each inner list contains:\\n        - Document index (1-based)\\n        - Document sentiment\\n        - Document confidence scores (positive, neutral, negative)\\n        - Sentence text\\n        - Sentence sentiment\\n        - Sentence confidence scores (positive, neutral, negative)\\n        - Target text\\n        - Target sentiment\\n        - Target confidence scores (positive, negative)\\n        - Assessment text\\n        - Assessment sentiment\\n        - Assessment confidence scores (positive, negative)\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_sentiment.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "headers"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Documents(arg1)\", \"AzureKey(arg2)\", \"AzureURL(arg3)\", \"DocIndex\", \"DSent\", \"DPos\", \"DNeu\", \"DNeg\", \"Sentence\", \"SSent\", \"SPos\", \"SNeu\", \"SNeg\", \"Aspect\", \"ASent\", \"APos\", \"ANeg\", \"Opinion\", \"OSent\", \"OPos\", \"ONeg\"]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\"Documents(arg1)\", \"AzureKey(arg2)\", \"AzureURL(arg3)\", \"DocIndex\", \"DSent\", \"DPos\", \"DNeu\", \"DNeg\", \"Sentence\", \"SSent\", \"SPos\", \"SNeu\", \"SNeg\", \"Aspect\", \"ASent\", \"APos\", \"ANeg\", \"Opinion\", \"OSent\", \"OPos\", \"ONeg\"]\n",
    "json.dumps(headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
